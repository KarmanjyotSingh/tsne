{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "\n",
    "This notebook implements the t-SNE mapping for visualising higher dimensional datasets into lower dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "\n",
    "Reducing the higher dimensional data to 30 major components using the PCA decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduceDimensionality(data, n_components = 30):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function aims to reduce the higher dimensional data to lower dimensions [ = 30 ]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : data frame object with last column being the label corresponding to the given data samples\n",
    "    n_components : number of components to be reduced to\n",
    "\n",
    "    \"\"\"\n",
    "    # standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    x = scaler.fit_transform(x)\n",
    "    # apply PCA\n",
    "    pca = PCA(n_components = n_components)\n",
    "    x = pca.fit_transform(x)\n",
    "    # concatenate the data\n",
    "    data = np.concatenate((x, y.reshape(-1,1)), axis = 1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPCA(data,title):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to plot the generated PCA plot , only in 2 dimensions considering the major 2 PCA components \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : data frame object with last column being the label corresponding to the given data samples\n",
    "    title : title of the plot\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(data[:, 0], data[:, 1], alpha=0.5,c=data[:,-1])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Matrice Q in the lower dimensional space\n",
    "\n",
    "Calculating the similarity matrix, amongst the points in the lower dimensions. Wherein each element in the matrix is given by : \n",
    "\n",
    "$ q_{i, j} = \\frac{(1 + ||y_i - y_j||^2)^{-1}}{\\Sigma_{k\\neq l}(1+||y_k-y_l||^2)^{-1}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePairwiseDistances(X):\n",
    "    \"\"\"\n",
    "    Function to compute the pairwise distances between the data points in the higher dimensional space\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    X : data points in the higher dimensional space\n",
    "\n",
    "    \"\"\"\n",
    "    pairwise_distances = np.sum(X**2, axis=1).reshape(-1,1) + np.sum(X**2, axis=1) - 2 * np.dot(X, X.T)\n",
    "    return pairwise_distances\n",
    "\n",
    "def computeQMatrix(Y):\n",
    "    \"\"\"\n",
    "    Function to compute the Q matrix for the given data points\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "\n",
    "    Y : data points in the lower dimensional space\n",
    "\n",
    "    \"\"\"\n",
    "    pairwise_distances=computePairwiseDistances(Y)\n",
    "    pairwise_distances=1. - pairwise_distances\n",
    "    inverse_distances=np.power(pairwise_distances,-1)\n",
    "    np.fill_diagonal(inverse_distances,0.)\n",
    "    return inverse_distances/(inverse_distances.sum(axis=1)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Search and Probobility matrix functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code \n",
    "\n",
    "def computeProbMatrix(pairwise_dist,sigmas):\n",
    "    \"\"\"\n",
    "    Function to compute the probability matrix for the given data points\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "\n",
    "    Y : data points in the lower dimensional space\n",
    "\n",
    "    \"\"\"\n",
    "    if sigmas is None:\n",
    "        sigmas = np.ones((pairwise_dist.shape[0],1))\n",
    "\n",
    "    pairwise_dist=np.array(pairwise_dist)\n",
    "    sigmas=np.array(sigmas)\n",
    "    sigmas=sigmas.reshape(1,-1)\n",
    "    ratio=pairwise_dist/(2.*np.square(sigmas.T))\n",
    "    ratios=-1.*ratio\n",
    "    probMatrix=np.exp(ratios)\n",
    "    np.fill_diagonal(probMatrix,0.)\n",
    "    return probMatrix/(probMatrix.sum(axis=1)).reshape(-1,1)\n",
    "\n",
    "def BinarySearch(comparator, target):\n",
    "    \"\"\"\n",
    "    Function to perform binary search on the given comparator function\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    comparator : comparator function\n",
    "    target : target value to be searched for\n",
    "\n",
    "    \"\"\"\n",
    "    lower_bound=1e-18\n",
    "    upper_bound=1000\n",
    "    iterations=0\n",
    "    sensitivity=1e-10\n",
    "    mid=(upper_bound+lower_bound)/2\n",
    "    while np.abs(comparator(mid)-target)>sensitivity:\n",
    "        mid=(upper_bound-lower_bound)/2\n",
    "        if comparator(mid)>target:\n",
    "            upper_bound=mid\n",
    "        else:\n",
    "            lower_bound=mid\n",
    "        iterations=iterations+1\n",
    "        if(iterations==10000):\n",
    "            break\n",
    "    return mid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the optimal variances using perplexity\n",
    "\n",
    "- Perplexity is defined as \n",
    "    $$\n",
    "    Perp(P_i) = 2^{H(P_i)}\n",
    "    $$\n",
    "    Where $H$ is the shanon's entropy.\n",
    "\n",
    "- Shanon's entropy is defined as:\n",
    "    $$\n",
    "    H(P_i) = - \\sum_i  p_{j|i} \\log(p_{j|i})\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerplexity(pairwise_dist, sigmas):\n",
    "    \"\"\"\n",
    "    Function to compute the perplexity for the pairwise distances\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    pairwise_dist : pairwise distances between the data points\n",
    "    sigmas : sigmas corresponding to the data points\n",
    "    \"\"\"\n",
    "    # compute the probability matrix\n",
    "    prob_matrix = computeProbMatrix(pairwise_dist,sigmas)\n",
    "    # compute the entropy\n",
    "    H = np.sum(prob_matrix * np.log2(prob_matrix + 1e-12), axis=1)\n",
    "    # compute the perplexity\n",
    "    perplexity = 2**(-H)\n",
    "    return perplexity\n",
    "\n",
    "def computeOptimalVariances(pairwise_dist, perplexity):\n",
    "    \"\"\"\n",
    "    Function to compute the optimal variances for the given perplexity\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    pairwise_dist : pairwise distances between the data points\n",
    "    perplexity : perplexity corresponding to the data points\n",
    "\n",
    "    \"\"\"\n",
    "    # compute the optimal variances\n",
    "    sigmas = np.zeros((pairwise_dist.shape[0]))\n",
    "    for i in range(pairwise_dist.shape[0]):\n",
    "        comparator = lambda sigma: computePerplexity(pairwise_dist[i:i+1,:], np.array(sigma))\n",
    "        sigmas[i] = BinarySearch(comparator, perplexity)\n",
    "    return sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing pairwise affinities according to the best value of variances\n",
    "\n",
    "The pairwise affinities are defines as the conditional probability $P_{j|i}$:\n",
    "$$\n",
    "p_{j|i} = \\frac{exp\\left({\\frac{-||x_i - x_j||^2}{2\\sigma_i^2}}\\right)}{\\sum_{k\\ne i }exp\\left({\\frac{-||x_i - x_k||^2}{2\\sigma_i^2}}\\right)}\n",
    "$$\n",
    "\n",
    "We then set the joint probabilityies $p_{ij}$ in the high-dimensional space to be the symmetrized conditional probabilities:\n",
    "$$\n",
    "p_{ij} = \\frac{p_{i|j} + p_{j|i}}{2n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeJointProbabilities(X, perplexity):\n",
    "    \"\"\"\n",
    "    Function to compute the joint probabilities for the given data points\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    X : data points in the higher dimensional space\n",
    "    perplexity : perplexity corresponding to the data points\n",
    "\n",
    "    \"\"\"\n",
    "    # compute the pairwise distances and optimal variances\n",
    "    pairwise_dist = computePairwiseDistances(X)\n",
    "    sigmas = computeOptimalVariances(pairwise_dist, perplexity)\n",
    "\n",
    "    # compute the pairwise affinities\n",
    "    pairwise_affinities = computeProbMatrix(pairwise_dist, sigmas)\n",
    "    \n",
    "    # compute the joint probabilities\n",
    "    joint_probabilities = (pairwise_affinities + pairwise_affinities.T) / (2 * X.shape[0])\n",
    "\n",
    "    return joint_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "The gradient of the t-SNE cost function reduces to a simple form : \n",
    "\n",
    "$ \\frac{\\partial C}{\\partial y_i} = 4\\Sigma_{j} (p_{i, j} - q_{i, j})(y_i - y_j)(1 + ||y_i-y_j||^2)^{-1}$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveFunction(Y,P,Q):\n",
    "    \"\"\"\n",
    "    Function to calculate the main objective function of t-SNE\n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y : The data points in the lower dimensional space\n",
    "    P : The joint probability distribution of the data points in the high dimensional space\n",
    "    Q : The joint probability distribution of the data points in the low dimensional space\n",
    "   \n",
    "    \"\"\"\n",
    "    # difference is a nxn matrix\n",
    "    difference = P - Q\n",
    "    pq_expanded = np.expand_dims(difference, 2)\n",
    "    y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)\n",
    "    distances_expanded = np.expand_dims(inv_distances, 2)\n",
    "    y_diffs_wt = y_diffs * distances_expanded\n",
    "    grad = 4. * (pq_expanded * y_diffs_wt).sum(1)\n",
    "    print(\"GRAD SHAPE :\",grad.shape)\n",
    "    return grad\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(Y,P,learningRate= 200.0 , momentum = 0.9, maxIterations = 1000):\n",
    "   \n",
    "    \"\"\"\n",
    "    Performs the gradient descent step for t-SNE algorithm \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    learningRate : learning rate for the gradient descent step\n",
    "\n",
    "    momentum : momentum for the gradient descent step\n",
    "\n",
    "    maxIterations : maximum number of iterations for the gradient descent step\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # store the variation of the points in gradient descent steps\n",
    "    Y_iterations = []\n",
    "\n",
    "    Y_t1 = Y.copy()\n",
    "    Y_t2 = Y.copy()\n",
    "    for iteration in range(0,maxIterations):\n",
    "\n",
    "\n",
    "        Y_iterations.append(Y.copy().reshape(-1,2))\n",
    "        # the similarity matrix in the low dimensional space\n",
    "        Q = computeQMatrix(Y)\n",
    "        \n",
    "        # gradient is a 1-D array consisting of point-wise gradients \n",
    "        gradient = objectiveFunction(Y,P,Q) \n",
    "\n",
    "        modGradient = np.linalg.norm(gradient)\n",
    "\n",
    "        # update the points in the low dimensional space\n",
    "        Y = Y - learningRate * gradient + momentum * (Y_t1 - Y_t2) \n",
    "        # update the vector terms\n",
    "        Y_t2 = Y_t1.copy()\n",
    "        Y_t1 = Y.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset\n",
    "\n",
    "- Loading the mnist dataset and reducing it to a lower dimensional space using PCA and number of components as 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/mnist_train.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']\n",
    "data = df.drop('label', axis = 1)\n",
    "data = data.values\n",
    "data = np.concatenate((data, labels.values.reshape(-1,1)), axis = 1)\n",
    "data = reduceDimensionality(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot PCA\n",
    "plotPCA(data, 'PCA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
