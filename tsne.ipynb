{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "\n",
    "This notebook implements the t-SNE mapping for visualising higher dimensional datasets into lower dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "\n",
    "Reducing the higher dimensional data to 30 major components using the PCA decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduceDimensionality(data, n_components = 30):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function aims to reduce the higher dimensional data to lower dimensions [ = 30 ]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : data frame object with last column being the label corresponding to the given data samples\n",
    "    n_components : number of components to be reduced to\n",
    "\n",
    "    \"\"\"\n",
    "    # standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    x = scaler.fit_transform(x)\n",
    "    # apply PCA\n",
    "    pca = PCA(n_components = n_components)\n",
    "    x = pca.fit_transform(x)\n",
    "    # concatenate the data\n",
    "    data = np.concatenate((x, y.reshape(-1,1)), axis = 1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPCA(data,title):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to plot the generated PCA plot , only in 2 dimensions considering the major 2 PCA components \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : data frame object with last column being the label corresponding to the given data samples\n",
    "    title : title of the plot\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(data[:, 0], data[:, 1], alpha=0.5,c=data[:,-1])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Matrice Q in the lower dimensional space\n",
    "\n",
    "Calculating the similarity matrix, amongst the points in the lower dimensions. Wherein each element in the matrix is given by : \n",
    "\n",
    "$ q_{i, j} = \\frac{(1 + ||y_i - y_j||^2)^{-1}}{\\Sigma_{k\\neq l}(1+||y_k-y_l||^2)^{-1}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeQMatrix(Y):\n",
    "    \"\"\"\n",
    "    Function to compute the Q matrix for the given data points\n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "\n",
    "    Y : data points in the lower dimensional space\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Search fro Optimal Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "The gradient of the t-SNE cost function reduces to a simple form : \n",
    "\n",
    "$ \\frac{\\partial C}{\\partial y_i} = 4\\Sigma_{j} (p_{i, j} - q_{i, j})(y_i - y_j)(1 + ||y_i-y_j||^2)^{-1}$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveFunction(Y,P,Q):\n",
    "    \"\"\"\n",
    "    Function to calculate the main objective function of t-SNE\n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y : The data points in the lower dimensional space\n",
    "    P : The joint probability distribution of the data points in the high dimensional space\n",
    "    Q : The joint probability distribution of the data points in the low dimensional space\n",
    "   \n",
    "    \"\"\"\n",
    "    # difference is a nxn matrix\n",
    "    difference = P - Q\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(Y,P,learningRate= 200.0 , momentum = 0.9, maxIterations = 1000):\n",
    "   \n",
    "    \"\"\"\n",
    "    Performs the gradient descent step for t-SNE algorithm \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    learningRate : learning rate for the gradient descent step\n",
    "\n",
    "    momentum : momentum for the gradient descent step\n",
    "\n",
    "    maxIterations : maximum number of iterations for the gradient descent step\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # store the variation of the points in gradient descent steps\n",
    "    Y_iterations = []\n",
    "\n",
    "    Y_t1 = Y.copy()\n",
    "    Y_t2 = Y.copy()\n",
    "    for iteration in range(0,maxIterations):\n",
    "\n",
    "\n",
    "        Y_iterations.append(Y.copy().reshape(-1,2))\n",
    "        # the similarity matrix in the low dimensional space\n",
    "        Q = computeQMatrix(Y)\n",
    "        \n",
    "        # gradient is a 1-D array consisting of point-wise gradients \n",
    "        gradient = objectiveFunction(Y,P,Q) \n",
    "\n",
    "        modGradient = np.linalg.norm(gradient)\n",
    "\n",
    "        # update the points in the low dimensional space\n",
    "        Y = Y - learningRate * gradient + momentum * (Y_t1 - Y_t2) \n",
    "        # update the vector terms\n",
    "        Y_t2 = Y_t1.copy()\n",
    "        Y_t1 = Y.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset\n",
    "\n",
    "- Loading the mnist dataset and reducing it to a lower dimensional space using PCA and number of components as 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mnist_train.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']\n",
    "data = df.drop('label', axis = 1)\n",
    "data = data.values\n",
    "data = np.concatenate((data, labels.values.reshape(-1,1)), axis = 1)\n",
    "data = reduceDimensionality(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot PCA\n",
    "plotPCA(data, 'PCA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
